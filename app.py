import os
import requests  # Ä‘á»ƒ báº¯t lá»—i timeout rÃµ rÃ ng
import streamlit as st
from rag import RAGIndex
from models import LLMProvider
from prompts import SYSTEM_PROMPT
from web_ingest import load_vendor_urls, fetch_vendor_docs

st.set_page_config(page_title="React Native Course Assistant", page_icon="ğŸ“±", layout="wide")

# Sidebar
with st.sidebar:
    st.title("âš™ï¸ Cáº¥u hÃ¬nh")
    provider = os.getenv("PROVIDER", "github").lower()
    provider = st.selectbox("Provider", ["github", "google"], index=0 if provider=="github" else 1)
    use_rag = st.checkbox("DÃ¹ng RAG (trÃ­ch tÃ i liá»‡u)", value=True)
    use_local_docs = st.checkbox("DÃ¹ng tÃ i liá»‡u ná»™i bá»™ (data/)", value=True)
    use_vendor_docs = st.checkbox("DÃ¹ng nguá»“n vendor (sources.yaml)", value=True)
    top_k = st.slider("Sá»‘ Ä‘oáº¡n trÃ­ch dáº«n (k)", 1, 8, 4)
    temperature = st.slider("Nhiá»‡t Ä‘á»™ (creativity)", 0.0, 1.0, 0.3)

    # NÃºt test + placeholder hiá»ƒn thá»‹ káº¿t quáº£
    test_clicked = st.button("ğŸ§ª Test káº¿t ná»‘i LLM")
    ping_placeholder = st.empty()

    st.markdown("---")
    st.caption("Quáº£n lÃ½ API keys trong Streamlit Secrets. KhÃ´ng commit secrets lÃªn GitHub.")

# Cache resources
@st.cache_resource(show_spinner=True)
def load_index():
    idx = RAGIndex(data_dir="data")
    idx.build()  # chá»‰ ná»™i bá»™ trÆ°á»›c
    return idx

@st.cache_resource(show_spinner=True)
def load_llm(provider_choice: str):
    os.environ["PROVIDER"] = provider_choice
    return LLMProvider.from_env()

@st.cache_data(show_spinner=True, ttl=60*60*12)  # cache 12h
def get_vendor_docs():
    urls = load_vendor_urls("sources.yaml")
    return fetch_vendor_docs(urls)

st.title("ğŸ“± Trá»£ lÃ½ mÃ´n React Native (Giáº£ng viÃªn & Há»c viÃªn)")
st.caption("Há»i vá» khÃ¡i niá»‡m, best practices, lab/bÃ i táº­p (gá»£i Ã½), quy Ä‘á»‹nh mÃ´n há»c...")

# Session state
if "messages" not in st.session_state:
    st.session_state.messages = []
if "index" not in st.session_state:
    with st.spinner("Äang náº¡p tÃ i liá»‡u ná»™i bá»™ vÃ  xÃ¢y dá»±ng chá»‰ má»¥c..."):
        st.session_state.index = load_index()
if "llm" not in st.session_state:
    with st.spinner("Äang khá»Ÿi táº¡o mÃ´ hÃ¬nh..."):
        st.session_state.llm = load_llm(provider)

# Test ping
if test_clicked:
    try:
        if hasattr(st.session_state.llm, "ping"):
            with st.spinner("Äang kiá»ƒm tra káº¿t ná»‘i LLM..."):
                result = st.session_state.llm.ping()
        else:
            result = "âŒ ping() chÆ°a Ä‘Æ°á»£c cÃ i trong models.py â€” vui lÃ²ng cáº­p nháº­t models.py."
    except Exception as e:
        ping_placeholder.error(f"âŒ Ping exception: {e}")
    else:
        msg = str(result)
        (ping_placeholder.success if msg.startswith("âœ…") else ping_placeholder.error)(msg)

# Upload tÃ i liá»‡u
uploaded_files = st.file_uploader(
    "Táº£i thÃªm tÃ i liá»‡u (.md/.txt/.pdf) Ä‘á»ƒ tÄƒng cháº¥t lÆ°á»£ng tráº£ lá»i",
    type=["md", "txt", "pdf"], accept_multiple_files=True
)
if uploaded_files:
    added = st.session_state.index.add_uploaded_files(uploaded_files)
    if added:
        st.success(f"ÄÃ£ thÃªm {added} tÃ i liá»‡u táº£i lÃªn vÃ o chá»‰ má»¥c.")

# Vendor sync
vendor_docs = []
if use_vendor_docs:
    col1, col2 = st.columns([1,1])
    with col1:
        if st.button("ğŸ”„ Sync nguá»“n vendor"):
            st.cache_data.clear()
            st.experimental_rerun()
    with col2:
        st.caption("Sá»­a URLs trong sources.yaml náº¿u muá»‘n bá»• sung/giáº£m bá»›t nguá»“n.")
    with st.spinner("Äang táº£i nguá»“n vendor..."):
        vendor_docs = get_vendor_docs()
    if vendor_docs:
        st.info(f"ÄÃ£ náº¡p {len(vendor_docs)} trang vendor. Sáº½ dÃ¹ng Ä‘á»ƒ trÃ­ch dáº«n khi RAG báº­t.")

# Káº¿t há»£p nguá»“n theo lá»±a chá»n
st.session_state.index.reset_external_docs()
if use_vendor_docs and vendor_docs:
    st.session_state.index.add_external_docs(vendor_docs)
if not use_local_docs:
    st.session_state.index.disable_local_docs()

# Lá»‹ch sá»­ chat + trÃ­ch dáº«n
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])
        if "citations" in msg and msg["citations"]:
            with st.expander("Nguá»“n trÃ­ch dáº«n"):
                for c in msg["citations"]:
                    st.write(f"- {c['source']} (score: {c['score']:.3f})")

question = st.chat_input("Äáº·t cÃ¢u há»i vá» React Native, bÃ i táº­p, lab, yÃªu cáº§u mÃ´n há»c...")

def format_context(chunks):
    parts = []
    for i, ch in enumerate(chunks, 1):
        parts.append(f"[{i}] {ch['text']}\nSource: {ch['source']}")
    return "\n\n".join(parts)

if question:
    st.session_state.messages.append({"role": "user", "content": question})
    with st.chat_message("user"):
        st.markdown(question)

    with st.chat_message("assistant"):
        with st.spinner("Äang suy nghÄ©..."):
            retrieved = []
            context = ""
            if use_rag:
                retrieved = st.session_state.index.search(question, top_k=top_k)
                context = format_context(retrieved) if retrieved else ""
            try:
                answer = st.session_state.llm.generate_answer(
                    question=question,
                    context=context,
                    system_prompt=SYSTEM_PROMPT,
                    temperature=temperature
                )
                st.markdown(answer)
                citations = [{"source": r["source"], "score": r["score"]} for r in retrieved] if retrieved else []
                if citations:
                    with st.expander("Nguá»“n trÃ­ch dáº«n"):
                        for c in citations:
                            st.write(f"- {c['source']} (score: {c['score']:.3f})")
            except (requests.exceptions.ReadTimeout, requests.exceptions.ConnectTimeout) as e:
                st.error("LLM timeout. Thá»­ giáº£m 'Sá»‘ Ä‘oáº¡n trÃ­ch dáº«n (k)', hoáº·c há»i ngáº¯n hÆ¡n. Báº¡n cÅ©ng cÃ³ thá»ƒ tÄƒng timeout báº±ng cÃ¡ch Ä‘áº·t GITHUB_MODELS_TIMEOUT_READ trong Secrets (vÃ­ dá»¥ 180).")
                st.caption(f"Chi tiáº¿t: {e}")
                answer, citations = "Xin lá»—i, yÃªu cáº§u máº¥t quÃ¡ lÃ¢u Ä‘á»ƒ xá»­ lÃ½. Vui lÃ²ng thá»­ láº¡i.", []
            except Exception as e:
                st.error("CÃ³ lá»—i khi gá»i mÃ´ hÃ¬nh. Xem Logs Ä‘á»ƒ biáº¿t chi tiáº¿t.")
                st.caption(f"Chi tiáº¿t: {e}")
                answer, citations = "Xin lá»—i, tÃ´i khÃ´ng thá»ƒ tráº£ lá»i lÃºc nÃ y.", []
    st.session_state.messages.append({
        "role": "assistant",
        "content": answer,
        "citations": citations if use_rag else []
    })
